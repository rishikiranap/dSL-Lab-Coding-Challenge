{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Opinion Mining\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "At the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand the fundamentals of sentiment analysis\n",
    "2. Implement lexicon-based sentiment analysis\n",
    "3. Build machine learning models for sentiment classification\n",
    "4. Handle aspect-based sentiment analysis\n",
    "5. Process social media text and reviews\n",
    "6. Evaluate sentiment analysis systems\n",
    "7. Build real-time sentiment monitoring systems\n",
    "8. Handle multilingual sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sentiment Analysis\n",
    "\n",
    "Sentiment Analysis (also known as Opinion Mining) is the computational study of opinions, sentiments, and emotions expressed in text. It aims to determine the attitude of a speaker or writer with respect to some topic or the overall contextual polarity of a document.\n",
    "\n",
    "### Types of Sentiment Analysis:\n",
    "\n",
    "1. **Document-level**: Classify the overall sentiment of a document\n",
    "2. **Sentence-level**: Classify sentiment of individual sentences\n",
    "3. **Aspect-based**: Identify sentiment toward specific aspects/features\n",
    "4. **Fine-grained**: Multi-class classification (very positive, positive, neutral, negative, very negative)\n",
    "\n",
    "### Approaches to Sentiment Analysis:\n",
    "\n",
    "1. **Lexicon-based**: Using sentiment dictionaries and word lists\n",
    "2. **Machine Learning**: Training classifiers on labeled data\n",
    "3. **Deep Learning**: Using neural networks for complex pattern recognition\n",
    "4. **Hybrid**: Combining multiple approaches\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Social Media Monitoring**: Track brand sentiment on Twitter, Facebook, etc.\n",
    "- **Product Reviews**: Analyze customer feedback on e-commerce platforms\n",
    "- **Market Research**: Understand public opinion on products/services\n",
    "- **Political Analysis**: Monitor public sentiment toward politicians/policies\n",
    "- **Customer Service**: Automatically categorize support tickets by urgency/sentiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages",
    "!pip install numpy pandas matplotlib seaborn nltk scikit-learn textblob vaderSentiment tqdm torch transformers lime shap",
    "",
    "# Download required NLTK data",
    "import nltk",
    "for item in ['punkt', 'stopwords', 'vader_lexicon', 'wordnet', 'omw-1.4']:",
    "    nltk.download(item, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lexicon-Based Sentiment Analysis\n",
    "\n",
    "Lexicon-based approaches use predefined dictionaries of words associated with sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexiconSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Simple sentiment lexicons\n",
    "        self.positive_words = {\n",
    "            'excellent': 3, 'amazing': 3, 'outstanding': 3, 'fantastic': 3,\n",
    "            'great': 2, 'good': 2, 'nice': 2, 'wonderful': 2, 'awesome': 2,\n",
    "            'fine': 1, 'okay': 1, 'decent': 1, 'acceptable': 1,\n",
    "            'love': 3, 'like': 2, 'enjoy': 2, 'appreciate': 2,\n",
    "            'happy': 2, 'pleased': 2, 'satisfied': 2, 'delighted': 3\n",
    "        }\n",
    "        \n",
    "        self.negative_words = {\n",
    "            'terrible': -3, 'awful': -3, 'horrible': -3, 'disgusting': -3,\n",
    "            'bad': -2, 'poor': -2, 'disappointing': -2, 'unacceptable': -2,\n",
    "            'hate': -3, 'dislike': -2, 'annoying': -2, 'frustrating': -2,\n",
    "            'sad': -2, 'angry': -2, 'upset': -2, 'disappointed': -2,\n",
    "            'wrong': -1, 'problem': -1, 'issue': -1, 'difficult': -1\n",
    "        }\n",
    "        \n",
    "        # Intensity modifiers\n",
    "        self.intensifiers = {\n",
    "            'very': 1.5, 'extremely': 2.0, 'incredibly': 2.0, 'absolutely': 1.8,\n",
    "            'completely': 1.7, 'totally': 1.6, 'really': 1.3, 'quite': 1.2,\n",
    "            'rather': 1.1, 'pretty': 1.1, 'somewhat': 0.8, 'slightly': 0.7\n",
    "        }\n",
    "        \n",
    "        # Negation words\n",
    "        self.negations = {'not', 'no', 'never', 'neither', 'nobody', 'nothing', \n",
    "                         'nowhere', 'isn\\'t', 'aren\\'t', 'wasn\\'t', 'weren\\'t', \n",
    "                         'won\\'t', 'wouldn\\'t', 'don\\'t', 'doesn\\'t', 'didn\\'t',\n",
    "                         'can\\'t', 'couldn\\'t', 'shouldn\\'t', 'wouldn\\'t'}\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Basic text preprocessing\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        words = text.split()\n",
    "        return words\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment using lexicon-based approach\"\"\"\n",
    "        words = self.preprocess_text(text)\n",
    "        sentiment_score = 0\n",
    "        word_count = 0\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(words):\n",
    "            word = words[i]\n",
    "            \n",
    "            # Check for negation\n",
    "            negated = False\n",
    "            if i > 0 and words[i-1] in self.negations:\n",
    "                negated = True\n",
    "            \n",
    "            # Check for intensifiers\n",
    "            intensifier = 1.0\n",
    "            if i > 0 and words[i-1] in self.intensifiers:\n",
    "                intensifier = self.intensifiers[words[i-1]]\n",
    "            \n",
    "            # Calculate sentiment score\n",
    "            if word in self.positive_words:\n",
    "                score = self.positive_words[word] * intensifier\n",
    "                if negated:\n",
    "                    score = -score\n",
    "                sentiment_score += score\n",
    "                word_count += 1\n",
    "            elif word in self.negative_words:\n",
    "                score = self.negative_words[word] * intensifier\n",
    "                if negated:\n",
    "                    score = -score\n",
    "                sentiment_score += score\n",
    "                word_count += 1\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        # Normalize score\n",
    "        if word_count > 0:\n",
    "            sentiment_score = sentiment_score / word_count\n",
    "        \n",
    "        return self.classify_sentiment(sentiment_score), sentiment_score\n",
    "    \n",
    "    def classify_sentiment(self, score):\n",
    "        \"\"\"Classify sentiment based on score\"\"\"\n",
    "        if score > 0.5:\n",
    "            return 'positive'\n",
    "        elif score < -0.5:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "\n",
    "# Initialize and test lexicon-based analyzer\n",
    "lexicon_analyzer = LexiconSentimentAnalyzer()\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"This movie is absolutely fantastic!\",\n",
    "    \"I really hate this terrible product.\",\n",
    "    \"The service was okay, nothing special.\",\n",
    "    \"Not bad, but could be better.\",\n",
    "    \"I'm extremely disappointed with this purchase.\",\n",
    "    \"This is the best thing ever!\"\n",
    "]\n",
    "\n",
    "print(\"Lexicon-based Sentiment Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "for sentence in test_sentences:\n",
    "    sentiment, score = lexicon_analyzer.analyze_sentiment(sentence)\n",
    "    print(f\"Text: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment.upper()} (Score: {score:.2f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Pre-built Sentiment Analysis Tools\n",
    "\n",
    "Let's compare different sentiment analysis tools and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentComparator:\n",
    "    def __init__(self):\n",
    "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "        self.custom_analyzer = lexicon_analyzer\n",
    "    \n",
    "    def analyze_with_textblob(self, text):\n",
    "        \"\"\"Analyze sentiment using TextBlob\"\"\"\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        \n",
    "        if polarity > 0.1:\n",
    "            return 'positive', polarity\n",
    "        elif polarity < -0.1:\n",
    "            return 'negative', polarity\n",
    "        else:\n",
    "            return 'neutral', polarity\n",
    "    \n",
    "    def analyze_with_vader(self, text):\n",
    "        \"\"\"Analyze sentiment using VADER\"\"\"\n",
    "        scores = self.vader_analyzer.polarity_scores(text)\n",
    "        compound_score = scores['compound']\n",
    "        \n",
    "        if compound_score >= 0.05:\n",
    "            return 'positive', compound_score\n",
    "        elif compound_score <= -0.05:\n",
    "            return 'negative', compound_score\n",
    "        else:\n",
    "            return 'neutral', compound_score\n",
    "    \n",
    "    def compare_methods(self, texts):\n",
    "        \"\"\"Compare different sentiment analysis methods\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for text in texts:\n",
    "            # Custom lexicon-based\n",
    "            custom_sentiment, custom_score = self.custom_analyzer.analyze_sentiment(text)\n",
    "            \n",
    "            # TextBlob\n",
    "            textblob_sentiment, textblob_score = self.analyze_with_textblob(text)\n",
    "            \n",
    "            # VADER\n",
    "            vader_sentiment, vader_score = self.analyze_with_vader(text)\n",
    "            \n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'custom': (custom_sentiment, custom_score),\n",
    "                'textblob': (textblob_sentiment, textblob_score),\n",
    "                'vader': (vader_sentiment, vader_score)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_comparison(self, results):\n",
    "        \"\"\"Print comparison results in a formatted way\"\"\"\n",
    "        print(f\"{'Text':<40} {'Custom':<15} {'TextBlob':<15} {'VADER':<15}\")\n",
    "        print(\"=\"*85)\n",
    "        \n",
    "        for result in results:\n",
    "            text = result['text'][:37] + '...' if len(result['text']) > 40 else result['text']\n",
    "            custom = f\"{result['custom'][0]} ({result['custom'][1]:.2f})\"\n",
    "            textblob = f\"{result['textblob'][0]} ({result['textblob'][1]:.2f})\"\n",
    "            vader = f\"{result['vader'][0]} ({result['vader'][1]:.2f})\"\n",
    "            \n",
    "            print(f\"{text:<40} {custom:<15} {textblob:<15} {vader:<15}\")\n",
    "\n",
    "# Test comparison\n",
    "comparator = SentimentComparator()\n",
    "\n",
    "comparison_texts = [\n",
    "    \"I love this product! It's amazing!\",\n",
    "    \"This is the worst thing I've ever bought.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"I'm not happy with this purchase.\",\n",
    "    \"Absolutely fantastic! Highly recommend!\",\n",
    "    \"Meh, could be better.\",\n",
    "    \"I hate this so much!!!\",\n",
    "    \"Pretty good, but not perfect.\"\n",
    "]\n",
    "\n",
    "results = comparator.compare_methods(comparison_texts)\n",
    "print(\"Sentiment Analysis Method Comparison:\")\n",
    "print()\n",
    "comparator.print_comparison(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning-Based Sentiment Analysis\n",
    "\n",
    "Let's build machine learning models for sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "        self.models = {\n",
    "            'logistic_regression': LogisticRegression(random_state=42),\n",
    "            'naive_bayes': MultinomialNB(),\n",
    "            'svm': SVC(kernel='linear', random_state=42),\n",
    "            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        }\n",
    "        self.trained_models = {}\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def create_sample_dataset(self):\n",
    "        \"\"\"Create a sample dataset for demonstration\"\"\"\n",
    "        # Positive examples\n",
    "        positive_texts = [\n",
    "            \"I love this product! It's amazing and works perfectly.\",\n",
    "            \"Excellent quality and fast delivery. Highly recommend!\",\n",
    "            \"Best purchase I've made this year. Absolutely fantastic!\",\n",
    "            \"Great value for money. Very satisfied with my purchase.\",\n",
    "            \"Outstanding customer service and product quality.\",\n",
    "            \"This exceeded my expectations. Really impressed!\",\n",
    "            \"Wonderful product! Exactly what I was looking for.\",\n",
    "            \"Perfect! Works flawlessly and looks great.\",\n",
    "            \"Amazing quality and design. Love it!\",\n",
    "            \"Fantastic product! Would definitely buy again.\",\n",
    "            \"Super happy with this purchase. Great job!\",\n",
    "            \"Excellent build quality and performance.\",\n",
    "            \"This is awesome! Exactly as described.\",\n",
    "            \"Very impressed with the quality and features.\",\n",
    "            \"Outstanding value and excellent functionality.\"\n",
    "        ]\n",
    "        \n",
    "        # Negative examples\n",
    "        negative_texts = [\n",
    "            \"This product is terrible. Complete waste of money.\",\n",
    "            \"Worst purchase ever. Broke after one day.\",\n",
    "            \"Awful quality and terrible customer service.\",\n",
    "            \"Don't buy this! It's a scam and doesn't work.\",\n",
    "            \"Horrible experience. Product arrived damaged.\",\n",
    "            \"Very disappointed with this purchase. Poor quality.\",\n",
    "            \"This is garbage. Completely useless and overpriced.\",\n",
    "            \"Terrible design and extremely poor build quality.\",\n",
    "            \"Hate this product! Nothing but problems.\",\n",
    "            \"Absolutely awful. Regret buying this junk.\",\n",
    "            \"Disappointing quality and functionality. Avoid!\",\n",
    "            \"This is the worst product I've ever used.\",\n",
    "            \"Completely useless and poorly made.\",\n",
    "            \"Terrible value for money. Total ripoff.\",\n",
    "            \"Defective product with horrible support.\"\n",
    "        ]\n",
    "        \n",
    "        # Neutral examples\n",
    "        neutral_texts = [\n",
    "            \"It's okay, nothing special but does the job.\",\n",
    "            \"Average product with standard features.\",\n",
    "            \"Decent quality but could be better.\",\n",
    "            \"It works as expected, nothing more.\",\n",
    "            \"Standard product with basic functionality.\",\n",
    "            \"Acceptable quality for the price.\",\n",
    "            \"It's fine, meets basic requirements.\",\n",
    "            \"Ordinary product with typical features.\",\n",
    "            \"Not bad but not great either.\",\n",
    "            \"Average experience, nothing to complain about.\",\n",
    "            \"Standard quality and performance.\",\n",
    "            \"It's adequate for basic needs.\",\n",
    "            \"Neutral experience overall.\",\n",
    "            \"Basic product that does what it says.\",\n",
    "            \"Mediocre quality but functional.\"\n",
    "        ]\n",
    "        \n",
    "        # Combine data\n",
    "        texts = positive_texts + negative_texts + neutral_texts\n",
    "        labels = (['positive'] * len(positive_texts) + \n",
    "                 ['negative'] * len(negative_texts) + \n",
    "                 ['neutral'] * len(neutral_texts))\n",
    "        \n",
    "        return texts, labels\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocess text for ML models\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters but keep spaces\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Remove extra whitespaces\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def train_models(self, texts, labels):\n",
    "        \"\"\"Train multiple ML models\"\"\"\n",
    "        # Preprocess texts\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            processed_texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        # Vectorize text\n",
    "        X_train_vec = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = self.vectorizer.transform(X_test)\n",
    "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Train models\n",
    "        results = {}\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(X_train_vec, y_train)\n",
    "            \n",
    "            # Predict and evaluate\n",
    "            y_pred = model.predict(X_test_vec)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Store trained model\n",
    "            self.trained_models[name] = model\n",
    "            \n",
    "            results[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "        return results, X_test, y_test\n",
    "    \n",
    "    def predict_sentiment(self, text, model_name='logistic_regression'):\n",
    "        \"\"\"Predict sentiment for new text\"\"\"\n",
    "        if model_name not in self.trained_models:\n",
    "            raise ValueError(f\"Model {model_name} not trained yet\")\n",
    "        \n",
    "        processed_text = self.preprocess_text(text)\n",
    "        text_vec = self.vectorizer.transform([processed_text])\n",
    "        \n",
    "        model = self.trained_models[model_name]\n",
    "        prediction = model.predict(text_vec)[0]\n",
    "        \n",
    "        # Get probability scores if available\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probabilities = model.predict_proba(text_vec)[0]\n",
    "            prob_dict = dict(zip(model.classes_, probabilities))\n",
    "            return prediction, prob_dict\n",
    "        else:\n",
    "            return prediction, None\n",
    "    \n",
    "    def get_top_features(self, model_name='logistic_regression', n_features=10):\n",
    "        \"\"\"Get top features for sentiment prediction\"\"\"\n",
    "        if model_name not in self.trained_models:\n",
    "            return None\n",
    "        \n",
    "        model = self.trained_models[model_name]\n",
    "        \n",
    "        if hasattr(model, 'coef_'):\n",
    "            # For linear models\n",
    "            if len(model.classes_) == 2:\n",
    "                # Binary classification\n",
    "                coef = model.coef_[0]\n",
    "                top_positive = np.argsort(coef)[-n_features:]\n",
    "                top_negative = np.argsort(coef)[:n_features]\n",
    "                \n",
    "                return {\n",
    "                    'positive': [(self.feature_names[i], coef[i]) for i in reversed(top_positive)],\n",
    "                    'negative': [(self.feature_names[i], coef[i]) for i in top_negative]\n",
    "                }\n",
    "            else:\n",
    "                # Multi-class classification\n",
    "                features_by_class = {}\n",
    "                for i, class_name in enumerate(model.classes_):\n",
    "                    coef = model.coef_[i]\n",
    "                    top_indices = np.argsort(coef)[-n_features:]\n",
    "                    features_by_class[class_name] = [\n",
    "                        (self.feature_names[j], coef[j]) for j in reversed(top_indices)\n",
    "                    ]\n",
    "                return features_by_class\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Initialize and train ML models\n",
    "ml_analyzer = MLSentimentAnalyzer()\n",
    "\n",
    "# Create sample dataset\n",
    "texts, labels = ml_analyzer.create_sample_dataset()\n",
    "print(f\"Created dataset with {len(texts)} samples\")\n",
    "print(f\"Label distribution: {Counter(labels)}\")\n",
    "print(\"\\nTraining ML models...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Train models\n",
    "results, X_test, y_test = ml_analyzer.train_models(texts, labels)\n",
    "\n",
    "# Test predictions\n",
    "test_texts = [\n",
    "    \"This product is absolutely wonderful!\",\n",
    "    \"I hate this terrible quality.\",\n",
    "    \"It's an average product, nothing special.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting predictions:\")\n",
    "print(\"=\" * 30)\n",
    "for text in test_texts:\n",
    "    prediction, probabilities = ml_analyzer.predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    if probabilities:\n",
    "        print(f\"Probabilities: {probabilities}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis and Model Interpretation\n",
    "\n",
    "Understanding what features contribute to sentiment predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top features\n",
    "print(\"Top Features for Sentiment Classification:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "top_features = ml_analyzer.get_top_features('logistic_regression', n_features=10)\n",
    "if top_features:\n",
    "    for sentiment, features in top_features.items():\n",
    "        print(f\"\\n{sentiment.upper()} sentiment features:\")\n",
    "        for feature, weight in features:\n",
    "            print(f\"  {feature}: {weight:.3f}\")\n",
    "\n",
    "# Visualize model performance\n",
    "def plot_model_comparison(results):\n",
    "    \"\"\"Plot comparison of model accuracies\"\"\"\n",
    "    models = list(results.keys())\n",
    "    accuracies = [results[model]['accuracy'] for model in models]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "plot_model_comparison(results)\n",
    "\n",
    "# Plot confusion matrix for best model\n",
    "best_model = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "print(f\"\\nBest model: {best_model} with accuracy: {results[best_model]['accuracy']:.3f}\")\n",
    "\n",
    "plot_confusion_matrix(results[best_model]['y_test'], \n",
    "                     results[best_model]['y_pred'], \n",
    "                     f'Confusion Matrix - {best_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aspect-Based Sentiment Analysis\n",
    "\n",
    "Analyzing sentiment toward specific aspects or features of products/services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectBasedSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Define aspect categories and related keywords\n",
    "        self.aspect_keywords = {\n",
    "            'quality': ['quality', 'build', 'material', 'construction', 'durability', 'craftsmanship'],\n",
    "            'price': ['price', 'cost', 'expensive', 'cheap', 'value', 'money', 'affordable'],\n",
    "            'service': ['service', 'support', 'staff', 'help', 'customer', 'representative'],\n",
    "            'delivery': ['delivery', 'shipping', 'arrival', 'packaging', 'fast', 'slow'],\n",
    "            'usability': ['easy', 'difficult', 'user', 'interface', 'simple', 'complex', 'intuitive'],\n",
    "            'design': ['design', 'look', 'appearance', 'style', 'color', 'aesthetic', 'beautiful']\n",
    "        }\n",
    "        \n",
    "        # Sentiment words with aspect context\n",
    "        self.aspect_sentiment = {\n",
    "            'quality': {\n",
    "                'positive': ['excellent', 'high', 'great', 'superior', 'premium', 'top'],\n",
    "                'negative': ['poor', 'low', 'bad', 'inferior', 'cheap', 'terrible']\n",
    "            },\n",
    "            'price': {\n",
    "                'positive': ['affordable', 'reasonable', 'fair', 'good', 'value', 'cheap'],\n",
    "                'negative': ['expensive', 'overpriced', 'costly', 'pricey', 'steep']\n",
    "            },\n",
    "            'service': {\n",
    "                'positive': ['helpful', 'friendly', 'excellent', 'responsive', 'professional'],\n",
    "                'negative': ['rude', 'unhelpful', 'slow', 'poor', 'terrible', 'awful']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def extract_aspects(self, text):\n",
    "        \"\"\"Extract aspects mentioned in the text\"\"\"\n",
    "        words = text.lower().split()\n",
    "        detected_aspects = []\n",
    "        \n",
    "        for aspect, keywords in self.aspect_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in words:\n",
    "                    detected_aspects.append(aspect)\n",
    "                    break\n",
    "        \n",
    "        return list(set(detected_aspects))\n",
    "    \n",
    "    def get_aspect_context(self, text, aspect, window_size=5):\n",
    "        \"\"\"Get context around aspect mentions\"\"\"\n",
    "        words = text.lower().split()\n",
    "        keywords = self.aspect_keywords[aspect]\n",
    "        contexts = []\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            if word in keywords:\n",
    "                start = max(0, i - window_size)\n",
    "                end = min(len(words), i + window_size + 1)\n",
    "                context = ' '.join(words[start:end])\n",
    "                contexts.append(context)\n",
    "        \n",
    "        return contexts\n",
    "    \n",
    "    def analyze_aspect_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment for each aspect\"\"\"\n",
    "        aspects = self.extract_aspects(text)\n",
    "        aspect_sentiments = {}\n",
    "        \n",
    "        for aspect in aspects:\n",
    "            contexts = self.get_aspect_context(text, aspect)\n",
    "            \n",
    "            if contexts:\n",
    "                # Analyze sentiment of each context\n",
    "                sentiment_scores = []\n",
    "                for context in contexts:\n",
    "                    # Use VADER for context sentiment\n",
    "                    vader_score = self.vader_analyzer.polarity_scores(context)\n",
    "                    sentiment_scores.append(vader_score['compound'])\n",
    "                \n",
    "                # Average sentiment for the aspect\n",
    "                avg_sentiment = np.mean(sentiment_scores)\n",
    "                \n",
    "                # Classify sentiment\n",
    "                if avg_sentiment >= 0.05:\n",
    "                    sentiment_label = 'positive'\n",
    "                elif avg_sentiment <= -0.05:\n",
    "                    sentiment_label = 'negative'\n",
    "                else:\n",
    "                    sentiment_label = 'neutral'\n",
    "                \n",
    "                aspect_sentiments[aspect] = {\n",
    "                    'sentiment': sentiment_label,\n",
    "                    'score': avg_sentiment,\n",
    "                    'contexts': contexts\n",
    "                }\n",
    "        \n",
    "        return aspect_sentiments\n",
    "    \n",
    "    def analyze_review(self, review_text):\n",
    "        \"\"\"Comprehensive review analysis\"\"\"\n",
    "        # Overall sentiment\n",
    "        overall_sentiment = self.vader_analyzer.polarity_scores(review_text)\n",
    "        \n",
    "        # Aspect-based sentiment\n",
    "        aspect_sentiments = self.analyze_aspect_sentiment(review_text)\n",
    "        \n",
    "        return {\n",
    "            'overall_sentiment': overall_sentiment,\n",
    "            'aspect_sentiments': aspect_sentiments,\n",
    "            'aspects_mentioned': list(aspect_sentiments.keys())\n",
    "        }\n",
    "\n",
    "# Initialize aspect-based analyzer\n",
    "aspect_analyzer = AspectBasedSentimentAnalyzer()\n",
    "\n",
    "# Test with sample reviews\n",
    "sample_reviews = [\n",
    "    \"The product quality is excellent and the price is very reasonable. However, the delivery was slow and the customer service was unhelpful.\",\n",
    "    \"Great design and beautiful appearance, but the build quality is poor. The interface is intuitive and easy to use.\",\n",
    "    \"Overpriced for what you get. The material feels cheap and the construction is terrible. Would not recommend.\",\n",
    "    \"Fast delivery and great packaging. The customer support was very helpful and professional. Good value for money.\"\n",
    "]\n",
    "\n",
    "print(\"Aspect-Based Sentiment Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, review in enumerate(sample_reviews, 1):\n",
    "    print(f\"\\nReview {i}: {review}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    analysis = aspect_analyzer.analyze_review(review)\n",
    "    \n",
    "    # Overall sentiment\n",
    "    overall = analysis['overall_sentiment']\n",
    "    print(f\"Overall Sentiment: {overall['compound']:.3f} (Positive: {overall['pos']:.3f}, Negative: {overall['neg']:.3f}, Neutral: {overall['neu']:.3f})\")\n",
    "    \n",
    "    # Aspect sentiments\n",
    "    print(\"\\nAspect Sentiments:\")\n",
    "    for aspect, sentiment_info in analysis['aspect_sentiments'].items():\n",
    "        print(f\"  {aspect.upper()}: {sentiment_info['sentiment']} (Score: {sentiment_info['score']:.3f})\")\n",
    "        print(f\"    Context: {sentiment_info['contexts'][0]}\")\n",
    "    \n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Social Media Sentiment Analysis\n",
    "\n",
    "Handling challenges specific to social media text (emoji, hashtags, informal language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialMediaSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Emoji sentiment mapping\n",
    "        self.emoji_sentiment = {\n",
    "            'üòÄ': 0.8, 'üòÉ': 0.8, 'üòÑ': 0.9, 'üòÅ': 0.8, 'üòä': 0.7,\n",
    "            'üòç': 0.9, 'ü•∞': 0.9, 'üòò': 0.8, 'üòé': 0.6, 'üëç': 0.7,\n",
    "            'üëè': 0.7, '‚ù§Ô∏è': 0.9, 'üíï': 0.8, 'üíñ': 0.8, 'üî•': 0.6,\n",
    "            'üò¢': -0.7, 'üò≠': -0.8, 'üò†': -0.8, 'üò°': -0.9, 'üëé': -0.7,\n",
    "            'üíî': -0.8, 'üò§': -0.6, 'üò©': -0.7, 'üò´': -0.7, 'ü§Æ': -0.9,\n",
    "            'üôÑ': -0.4, 'üòí': -0.5, 'üòï': -0.4, 'üòû': -0.6, 'üòü': -0.5,\n",
    "            'üòê': 0.0, 'üòë': 0.0, 'ü§î': 0.0, 'ü§∑': 0.0\n",
    "        }\n",
    "        \n",
    "        # Internet slang and abbreviations\n",
    "        self.slang_mapping = {\n",
    "            'lol': 'laugh out loud',\n",
    "            'lmao': 'laughing my ass off',\n",
    "            'rofl': 'rolling on floor laughing',\n",
    "            'omg': 'oh my god',\n",
    "            'wtf': 'what the f***',\n",
    "            'smh': 'shaking my head',\n",
    "            'tbh': 'to be honest',\n",
    "            'imo': 'in my opinion',\n",
    "            'fyi': 'for your information',\n",
    "            'afaik': 'as far as i know',\n",
    "            'idk': 'i do not know',\n",
    "            'nvm': 'never mind',\n",
    "            'thx': 'thanks',\n",
    "            'pls': 'please',\n",
    "            'ur': 'your',\n",
    "            'u': 'you'\n",
    "        }\n",
    "        \n",
    "        # Intensifiers in social media\n",
    "        self.intensifiers = {\n",
    "            'sooo': 2.0, 'soooo': 2.5, 'sooooo': 3.0,\n",
    "            'verrry': 1.5, 'verrrry': 2.0,\n",
    "            'reallyyyy': 2.0, 'reallyyy': 1.8,\n",
    "            'amazingggg': 2.0, 'awesomeee': 1.8,\n",
    "            'terribleee': -1.8, 'awfulll': -2.0\n",
    "        }\n",
    "        \n",
    "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def extract_emoji_sentiment(self, text):\n",
    "        \"\"\"Extract sentiment from emojis\"\"\"\n",
    "        emoji_scores = []\n",
    "        for char in text:\n",
    "            if char in self.emoji_sentiment:\n",
    "                emoji_scores.append(self.emoji_sentiment[char])\n",
    "        \n",
    "        if emoji_scores:\n",
    "            return np.mean(emoji_scores)\n",
    "        return 0.0\n",
    "    \n",
    "    def preprocess_social_media_text(self, text):\n",
    "        \"\"\"Preprocess social media text\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Expand contractions\n",
    "        contractions = {\n",
    "            \"won't\": \"will not\", \"can't\": \"cannot\", \"n't\": \" not\",\n",
    "            \"'re\": \" are\", \"'ve\": \" have\", \"'ll\": \" will\",\n",
    "            \"'d\": \" would\", \"'m\": \" am\"\n",
    "        }\n",
    "        for contraction, expansion in contractions.items():\n",
    "            text = text.replace(contraction, expansion)\n",
    "        \n",
    "        # Replace slang\n",
    "        words = text.split()\n",
    "        words = [self.slang_mapping.get(word, word) for word in words]\n",
    "        text = ' '.join(words)\n",
    "        \n",
    "        # Handle repeated characters (e.g., \"sooo\" -> \"so\")\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "        \n",
    "        # Remove hashtags but keep the content\n",
    "        text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "        \n",
    "        # Remove mentions\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def analyze_social_media_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment of social media text\"\"\"\n",
    "        # Extract emoji sentiment\n",
    "        emoji_sentiment = self.extract_emoji_sentiment(text)\n",
    "        \n",
    "        # Preprocess text\n",
    "        processed_text = self.preprocess_social_media_text(text)\n",
    "        \n",
    "        # Analyze text sentiment\n",
    "        if processed_text:\n",
    "            text_sentiment = self.vader_analyzer.polarity_scores(processed_text)\n",
    "            text_score = text_sentiment['compound']\n",
    "        else:\n",
    "            text_score = 0.0\n",
    "        \n",
    "        # Combine emoji and text sentiment\n",
    "        combined_score = (text_score + emoji_sentiment) / 2 if emoji_sentiment != 0 else text_score\n",
    "        \n",
    "        # Classify sentiment\n",
    "        if combined_score >= 0.05:\n",
    "            sentiment_label = 'positive'\n",
    "        elif combined_score <= -0.05:\n",
    "            sentiment_label = 'negative'\n",
    "        else:\n",
    "            sentiment_label = 'neutral'\n",
    "        \n",
    "        return {\n",
    "            'sentiment': sentiment_label,\n",
    "            'combined_score': combined_score,\n",
    "            'text_score': text_score,\n",
    "            'emoji_score': emoji_sentiment,\n",
    "            'processed_text': processed_text\n",
    "        }\n",
    "    \n",
    "    def analyze_hashtag_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment of hashtags\"\"\"\n",
    "        hashtags = re.findall(r'#(\\w+)', text.lower())\n",
    "        hashtag_sentiments = {}\n",
    "        \n",
    "        for hashtag in hashtags:\n",
    "            # Simple sentiment analysis of hashtag content\n",
    "            sentiment_score = self.vader_analyzer.polarity_scores(hashtag)['compound']\n",
    "            hashtag_sentiments[hashtag] = sentiment_score\n",
    "        \n",
    "        return hashtag_sentiments\n",
    "\n",
    "# Initialize social media analyzer\n",
    "social_analyzer = SocialMediaSentimentAnalyzer()\n",
    "\n",
    "# Test with social media posts\n",
    "social_media_posts = [\n",
    "    \"OMG this is sooo amazing! üòçüòç #love #bestever\",\n",
    "    \"Ugh, this is terrible üò§ Can't believe I wasted my money üí∏ #disappointed #fail\",\n",
    "    \"Just got my new phone! üì± It's pretty good tbh üëç #tech #newphone\",\n",
    "    \"Lmaooo this is hilarious üòÇüòÇüòÇ u guys need to see this! #funny #comedy\",\n",
    "    \"Feeling kinda meh about this üòê not great not terrible #neutral\",\n",
    "    \"This movie is awesomeee!!! üî•üî•üî• Go watch it rn! #movie #recommendation\",\n",
    "    \"Smh... another disappointing product üòû #quality #letdown\"\n",
    "]\n",
    "\n",
    "print(\"Social Media Sentiment Analysis Results:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, post in enumerate(social_media_posts, 1):\n",
    "    print(f\"\\nPost {i}: {post}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    analysis = social_analyzer.analyze_social_media_sentiment(post)\n",
    "    \n",
    "    print(f\"Sentiment: {analysis['sentiment'].upper()}\")\n",
    "    print(f\"Combined Score: {analysis['combined_score']:.3f}\")\n",
    "    print(f\"Text Score: {analysis['text_score']:.3f}\")\n",
    "    print(f\"Emoji Score: {analysis['emoji_score']:.3f}\")\n",
    "    print(f\"Processed Text: '{analysis['processed_text']}'\")\n",
    "    \n",
    "    # Analyze hashtags\n",
    "    hashtag_sentiments = social_analyzer.analyze_hashtag_sentiment(post)\n",
    "    if hashtag_sentiments:\n",
    "        print(\"Hashtag Sentiments:\")\n",
    "        for hashtag, score in hashtag_sentiments.items():\n",
    "            print(f\"  #{hashtag}: {score:.3f}\")\n",
    "    \n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-time Sentiment Monitoring\n",
    "\n",
    "Building a system for real-time sentiment monitoring and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "class RealTimeSentimentMonitor:\n",
    "    def __init__(self, window_size=100):\n",
    "        self.window_size = window_size\n",
    "        self.sentiment_buffer = queue.deque(maxlen=window_size)\n",
    "        self.sentiment_analyzer = social_analyzer\n",
    "        self.is_monitoring = False\n",
    "        self.sentiment_history = []\n",
    "        self.alerts = []\n",
    "        \n",
    "        # Alert thresholds\n",
    "        self.negative_threshold = -0.3\n",
    "        self.positive_threshold = 0.3\n",
    "        self.alert_window = 10  # Number of recent messages to check\n",
    "    \n",
    "    def add_message(self, text, timestamp=None):\n",
    "        \"\"\"Add a new message for sentiment analysis\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now()\n",
    "        \n",
    "        # Analyze sentiment\n",
    "        sentiment_result = self.sentiment_analyzer.analyze_social_media_sentiment(text)\n",
    "        \n",
    "        # Create message entry\n",
    "        message_entry = {\n",
    "            'timestamp': timestamp,\n",
    "            'text': text,\n",
    "            'sentiment': sentiment_result['sentiment'],\n",
    "            'score': sentiment_result['combined_score']\n",
    "        }\n",
    "        \n",
    "        # Add to buffer\n",
    "        self.sentiment_buffer.append(message_entry)\n",
    "        self.sentiment_history.append(message_entry)\n",
    "        \n",
    "        # Check for alerts\n",
    "        self.check_alerts()\n",
    "        \n",
    "        return message_entry\n",
    "    \n",
    "    def check_alerts(self):\n",
    "        \"\"\"Check for sentiment alerts\"\"\"\n",
    "        if len(self.sentiment_buffer) < self.alert_window:\n",
    "            return\n",
    "        \n",
    "        # Get recent messages\n",
    "        recent_messages = list(self.sentiment_buffer)[-self.alert_window:]\n",
    "        recent_scores = [msg['score'] for msg in recent_messages]\n",
    "        \n",
    "        avg_sentiment = np.mean(recent_scores)\n",
    "        \n",
    "        # Check for negative sentiment spike\n",
    "        if avg_sentiment <= self.negative_threshold:\n",
    "            alert = {\n",
    "                'type': 'negative_spike',\n",
    "                'timestamp': datetime.now(),\n",
    "                'avg_sentiment': avg_sentiment,\n",
    "                'message': f'Negative sentiment spike detected: {avg_sentiment:.3f}'\n",
    "            }\n",
    "            self.alerts.append(alert)\n",
    "        \n",
    "        # Check for positive sentiment spike\n",
    "        elif avg_sentiment >= self.positive_threshold:\n",
    "            alert = {\n",
    "                'type': 'positive_spike',\n",
    "                'timestamp': datetime.now(),\n",
    "                'avg_sentiment': avg_sentiment,\n",
    "                'message': f'Positive sentiment spike detected: {avg_sentiment:.3f}'\n",
    "            }\n",
    "            self.alerts.append(alert)\n",
    "    \n",
    "    def get_current_sentiment_stats(self):\n",
    "        \"\"\"Get current sentiment statistics\"\"\"\n",
    "        if not self.sentiment_buffer:\n",
    "            return None\n",
    "        \n",
    "        scores = [msg['score'] for msg in self.sentiment_buffer]\n",
    "        sentiments = [msg['sentiment'] for msg in self.sentiment_buffer]\n",
    "        \n",
    "        sentiment_counts = Counter(sentiments)\n",
    "        \n",
    "        return {\n",
    "            'total_messages': len(self.sentiment_buffer),\n",
    "            'avg_sentiment': np.mean(scores),\n",
    "            'sentiment_distribution': dict(sentiment_counts),\n",
    "            'positive_ratio': sentiment_counts.get('positive', 0) / len(sentiments),\n",
    "            'negative_ratio': sentiment_counts.get('negative', 0) / len(sentiments),\n",
    "            'neutral_ratio': sentiment_counts.get('neutral', 0) / len(sentiments)\n",
    "        }\n",
    "    \n",
    "    def get_recent_alerts(self, hours=1):\n",
    "        \"\"\"Get alerts from the last N hours\"\"\"\n",
    "        cutoff_time = datetime.now() - timedelta(hours=hours)\n",
    "        recent_alerts = [alert for alert in self.alerts if alert['timestamp'] >= cutoff_time]\n",
    "        return recent_alerts\n",
    "    \n",
    "    def simulate_message_stream(self, messages, interval=1):\n",
    "        \"\"\"Simulate a stream of messages for testing\"\"\"\n",
    "        print(\"Starting message stream simulation...\")\n",
    "        \n",
    "        for i, message in enumerate(messages):\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Processing message {i+1}: {message[:50]}...\")\n",
    "            \n",
    "            # Add message\n",
    "            entry = self.add_message(message)\n",
    "            print(f\"Sentiment: {entry['sentiment']} (Score: {entry['score']:.3f})\")\n",
    "            \n",
    "            # Check for new alerts\n",
    "            recent_alerts = self.get_recent_alerts(hours=0.1)  # Very recent alerts\n",
    "            if recent_alerts:\n",
    "                latest_alert = recent_alerts[-1]\n",
    "                if latest_alert['timestamp'] > datetime.now() - timedelta(seconds=5):\n",
    "                    print(f\"üö® ALERT: {latest_alert['message']}\")\n",
    "            \n",
    "            # Show current stats every 5 messages\n",
    "            if (i + 1) % 5 == 0:\n",
    "                stats = self.get_current_sentiment_stats()\n",
    "                print(f\"\\nüìä Current Stats:\")\n",
    "                print(f\"   Total Messages: {stats['total_messages']}\")\n",
    "                print(f\"   Average Sentiment: {stats['avg_sentiment']:.3f}\")\n",
    "                print(f\"   Distribution: {stats['sentiment_distribution']}\")\n",
    "            \n",
    "            time.sleep(interval)\n",
    "        \n",
    "        print(\"\\nMessage stream simulation completed!\")\n",
    "\n",
    "# Initialize real-time monitor\n",
    "monitor = RealTimeSentimentMonitor(window_size=50)\n",
    "\n",
    "# Simulate message stream\n",
    "simulation_messages = [\n",
    "    \"This is amazing! üòç Love it!\",\n",
    "    \"Great product, highly recommend! üëç\",\n",
    "    \"It's okay, nothing special üòê\",\n",
    "    \"Terrible quality, very disappointed üò†\",\n",
    "    \"Worst purchase ever! üò° Complete waste of money\",\n",
    "    \"Awful customer service, never buying again üò§\",\n",
    "    \"Disgusting! How is this even legal? ü§Æ\",\n",
    "    \"Absolutely horrible experience üò¢\",\n",
    "    \"Not too bad, could be better though\",\n",
    "    \"Actually pretty good! üòä Surprised me\",\n",
    "    \"Excellent quality and fast shipping! üî•\",\n",
    "    \"Outstanding service! 5 stars! ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\",\n",
    "    \"Perfect! Exactly what I wanted üíï\",\n",
    "    \"Incredible! Best purchase this year! üéâ\",\n",
    "    \"Fantastic product! Will buy again! üëè\"\n",
    "]\n",
    "\n",
    "# Run simulation\n",
    "monitor.simulate_message_stream(simulation_messages, interval=0.5)\n",
    "\n",
    "# Final statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "final_stats = monitor.get_current_sentiment_stats()\n",
    "print(f\"Total Messages Processed: {final_stats['total_messages']}\")\n",
    "print(f\"Average Sentiment Score: {final_stats['avg_sentiment']:.3f}\")\n",
    "print(f\"Positive Messages: {final_stats['positive_ratio']:.1%}\")\n",
    "print(f\"Negative Messages: {final_stats['negative_ratio']:.1%}\")\n",
    "print(f\"Neutral Messages: {final_stats['neutral_ratio']:.1%}\")\n",
    "\n",
    "print(f\"\\nTotal Alerts Generated: {len(monitor.alerts)}\")\n",
    "for alert in monitor.alerts:\n",
    "    print(f\"  {alert['type']}: {alert['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Sentiment Analysis Challenges\n",
    "\n",
    "Test your understanding with these progressive challenges!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Challenge 1: Emoji Enhancement\n",
    "Expand the emoji sentiment dictionary to include more emojis and create a more sophisticated emoji analysis system.\n",
    "\n",
    "**Requirements:**\n",
    "- Add at least 50 more emojis to the sentiment dictionary\n",
    "- Implement emoji combination analysis (e.g., üòÇüòÇüòÇ vs üòÇ)\n",
    "- Handle emoji modifiers (skin tones, etc.)\n",
    "\n",
    "**Success Criteria:**\n",
    "- Support 100+ emojis\n",
    "- Correctly handle emoji repetition intensity\n",
    "- Achieve 85%+ accuracy on emoji-heavy text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution for Challenge 1\n",
    "class EnhancedEmojiAnalyzer:\n",
    "    def __init__(self):\n",
    "        # TODO: Expand emoji dictionary\n",
    "        self.emoji_sentiment = {}\n",
    "        \n",
    "    def analyze_emoji_combinations(self, text):\n",
    "        # TODO: Analyze emoji combinations and repetitions\n",
    "        pass\n",
    "    \n",
    "    def handle_emoji_modifiers(self, text):\n",
    "        # TODO: Handle emoji modifiers\n",
    "        pass\n",
    "\n",
    "# Test your enhanced emoji analyzer\n",
    "test_texts = [\n",
    "    \"This is amazing! üòçüòçüòç\",\n",
    "    \"I'm so happy! üòäüëçüéâ\",\n",
    "    \"Terrible day üòûüòûüòû\"\n",
    "]\n",
    "\n",
    "# TODO: Test your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Domain-Specific Sentiment Lexicon\n",
    "Create specialized sentiment lexicons for different domains (healthcare, finance, technology).\n",
    "\n",
    "**Requirements:**\n",
    "- Build lexicons for 3 different domains\n",
    "- Implement domain detection\n",
    "- Compare performance across domains\n",
    "\n",
    "**Success Criteria:**\n",
    "- Each domain lexicon has 200+ words\n",
    "- Domain detection accuracy > 80%\n",
    "- Improved sentiment accuracy for domain-specific text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution for Challenge 2\n",
    "class DomainSpecificSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # TODO: Create domain-specific lexicons\n",
    "        self.domain_lexicons = {\n",
    "            'healthcare': {},\n",
    "            'finance': {},\n",
    "            'technology': {}\n",
    "        }\n",
    "        \n",
    "    def detect_domain(self, text):\n",
    "        # TODO: Implement domain detection\n",
    "        pass\n",
    "    \n",
    "    def analyze_domain_sentiment(self, text):\n",
    "        # TODO: Analyze sentiment using domain-specific lexicon\n",
    "        pass\n",
    "\n",
    "# Test domain-specific analysis\n",
    "domain_texts = [\n",
    "    \"The new treatment shows promising results for cancer patients.\",\n",
    "    \"The stock market crashed today, causing massive losses.\",\n",
    "    \"The new AI model outperforms all previous benchmarks.\"\n",
    "]\n",
    "\n",
    "# TODO: Test your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Challenge 3: Sarcasm Detection\n",
    "Build a system that can detect sarcasm in text, which often reverses the apparent sentiment.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement sarcasm detection using linguistic patterns\n",
    "- Adjust sentiment scores based on sarcasm probability\n",
    "- Handle different types of sarcasm (verbal irony, situational irony)\n",
    "\n",
    "**Success Criteria:**\n",
    "- Sarcasm detection accuracy > 75%\n",
    "- Improved sentiment accuracy on sarcastic text\n",
    "- Handle at least 5 different sarcasm patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution for Challenge 3\n",
    "class SarcasmDetector:\n",
    "    def __init__(self):\n",
    "        # TODO: Define sarcasm patterns and indicators\n",
    "        self.sarcasm_patterns = []\n",
    "        self.sarcasm_indicators = []\n",
    "    \n",
    "    def detect_sarcasm(self, text):\n",
    "        # TODO: Implement sarcasm detection logic\n",
    "        pass\n",
    "    \n",
    "    def adjust_sentiment_for_sarcasm(self, text, original_sentiment):\n",
    "        # TODO: Adjust sentiment based on sarcasm probability\n",
    "        pass\n",
    "\n",
    "# Test sarcasm detection\n",
    "sarcastic_texts = [\n",
    "    \"Oh great, another meeting. Just what I needed.\",\n",
    "    \"Wow, this is totally the best day ever.\",\n",
    "    \"Sure, because that's exactly what I wanted to hear.\"\n",
    "]\n",
    "\n",
    "# TODO: Test your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Comparative Sentiment Analysis\n",
    "Build a system that can analyze comparative statements and determine relative sentiment.\n",
    "\n",
    "**Requirements:**\n",
    "- Identify comparative statements (\"better than\", \"worse than\", etc.)\n",
    "- Extract compared entities\n",
    "- Determine relative sentiment between entities\n",
    "\n",
    "**Success Criteria:**\n",
    "- Identify 90%+ of comparative statements\n",
    "- Correctly extract compared entities\n",
    "- Assign relative sentiment scores accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution for Challenge 4\n",
    "class ComparativeSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # TODO: Define comparative patterns\n",
    "        self.comparative_patterns = []\n",
    "        self.comparative_keywords = []\n",
    "    \n",
    "    def identify_comparative_statements(self, text):\n",
    "        # TODO: Identify comparative statements\n",
    "        pass\n",
    "    \n",
    "    def extract_compared_entities(self, text):\n",
    "        # TODO: Extract entities being compared\n",
    "        pass\n",
    "    \n",
    "    def analyze_relative_sentiment(self, text):\n",
    "        # TODO: Analyze relative sentiment\n",
    "        pass\n",
    "\n",
    "# Test comparative analysis\n",
    "comparative_texts = [\n",
    "    \"iPhone is much better than Android phones.\",\n",
    "    \"This restaurant is worse than the one downtown.\",\n",
    "    \"The new model performs significantly better than the previous version.\"\n",
    "]\n",
    "\n",
    "# TODO: Test your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Challenge 5: Emotion Recognition Beyond Sentiment\n",
    "Build a system that can recognize specific emotions (joy, anger, fear, sadness, surprise, disgust) beyond just positive/negative sentiment.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement multi-emotion classification\n",
    "- Handle emotion intensity levels\n",
    "- Support emotion combinations\n",
    "\n",
    "**Success Criteria:**\n",
    "- Recognize 6+ distinct emotions\n",
    "- Achieve 70%+ accuracy on emotion classification\n",
    "- Handle mixed emotions correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution for Challenge 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class EmotionRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        # TODO: Define emotion categories and features\n",
    "        self.emotions = ['joy', 'anger', 'fear', 'sadness', 'surprise', 'disgust']\n",
    "        self.emotion_lexicons = {}\n",
    "        self.model = None\n",
    "    \n",
    "    def build_emotion_lexicons(self):\n",
    "        # TODO: Build emotion-specific lexicons\n",
    "        pass\n",
    "    \n",
    "    def extract_emotion_features(self, text):\n",
    "        # TODO: Extract features for emotion recognition\n",
    "        pass\n",
    "    \n",
    "    def train_emotion_classifier(self, training_data):\n",
    "        # TODO: Train multi-emotion classifier\n",
    "        pass\n",
    "    \n",
    "    def predict_emotions(self, text):\n",
    "        # TODO: Predict emotions with confidence scores\n",
    "        pass\n",
    "\n",
    "# TODO: Implement and test emotion recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: Cross-lingual Sentiment Analysis\n",
    "Build a sentiment analysis system that works across multiple languages without requiring translation.\n",
    "\n",
    "**Requirements:**\n",
    "- Support at least 3 languages (English, Spanish, French)\n",
    "- Use cross-lingual embeddings\n",
    "- Implement zero-shot learning for new languages\n",
    "\n",
    "**Success Criteria:**\n",
    "- Achieve consistent performance across languages\n",
    "- Handle code-switching (mixed languages)\n",
    "- Support zero-shot learning for new languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution for Challenge 6\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "class CrossLingualSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        # TODO: Initialize cross-lingual model\n",
    "        self.supported_languages = ['en', 'es', 'fr']\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "    \n",
    "    def detect_language(self, text):\n",
    "        # TODO: Implement language detection\n",
    "        pass\n",
    "    \n",
    "    def get_cross_lingual_embeddings(self, texts):\n",
    "        # TODO: Get cross-lingual embeddings\n",
    "        pass\n",
    "    \n",
    "    def train_cross_lingual_classifier(self, multilingual_data):\n",
    "        # TODO: Train classifier on multilingual data\n",
    "        pass\n",
    "    \n",
    "    def predict_sentiment_multilingual(self, text):\n",
    "        # TODO: Predict sentiment regardless of language\n",
    "        pass\n",
    "\n",
    "# Test multilingual sentiment analysis\n",
    "multilingual_texts = [\n",
    "    \"I love this product!\",  # English\n",
    "    \"¬°Me encanta este producto!\",  # Spanish\n",
    "    \"J'adore ce produit!\",  # French\n",
    "]\n",
    "\n",
    "# TODO: Test your implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}